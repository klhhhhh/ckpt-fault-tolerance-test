## DeepSpeed will automatically start based on the `hostfile`, and by default, it will use all GPUs on the current node. In contrast, `torchrun` requires the `--nproc_per_node` argument to specify how many GPUs to use.  
## DeepSpeed starts on a single node and automatically launches programs on other nodes via SSH, whereas `torchrun` requires manually starting the program on each node.  
## DeepSpeed follows the legacy behavior of `torch.distributed.launch` and automatically adds a `--local_rank` argument to your program, while `torchrun` retrieves `local_rank` from the `LOCAL_RANK` environment variable.  
## Therefore, DeepSpeed essentially automates the execution of `torch.distributed.launch` on each node and sets the `--nproc_per_node` parameter according to the `hostfile`.
## And we do not use srun command, directly use the command below on master node to run the program.